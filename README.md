The folders 
- `data_splits`
- `eval_scripts`
- `trial_submission`

are copied from the original github repo.
Link to the call: https://hitz-zentroa.github.io/shared-task-critical-questions-generation/

call: https://hitz-zentroa.github.io/shared-task-critical-questions-generation/


- [main shared task page](https://hitz-zentroa.github.io/shared-task-critical-questions-generation/)
- [Git-Repo](https://github.com/hitz-zentroa/shared-task-critical-questions-generation)
- [Examples](https://github.com/hitz-zentroa/shared-task-critical-questions-generation/blob/main/shared_task/utils/guidelines.pdf)


# Notes from the paper

[`Critical Questions Generation: Motivation and Challenges`](https://aclanthology.org/2024.conll-1.9.pdf)


    > Yet, instead of requiring the LLMs to output factual knowledge, could we use them to point at the missing or potentially uninformed claims? In other words, could we use LLMs to uncover the blind spots in the argumentation? To open this line of research, we ground our work on argumentation theory, which has for centuries been studying dia- logical exchanges of information. Specifically, we look into argumentation schemes, a set of abstract structures developed by systematically identifying common patterns of argumentation and outlining the defeasibility of these patterns. In these structures, the devices designed to find the blind spots in the arguments are called critical questions

    > Critical questions are the set of inquiries that could be asked in order to judge if an argument is acceptable or fallacious. 

    >  In the theoretical framework developed by Walton et al. (2008), argumentation schemes are represented as templates depicting the premises, the conclusion, and the critical questions of each scheme. This framework is useful to promote criti- cal thinking, since it allows uncovering fallacies by answering questions.

    > while theory-CQs are mostly about relations between premises, llm-CQs rather ask about evidences. Additionally, LLMs introduce a new type of questions: those asking about further definition of the terms used in the arguments.



- Goal: Uncover the blind spots in argumentation
- theory-cq: mainly focus on relations between premises
- llm_cq: asks about evidence, further definition of the terms used in the arguments

-> **misinformation definition**: is often generated by drawing invalid relations between claims and the premises provided to support these claims.
- pre-bunking: focused on techniques based on argumentation theory, which have the goal of evaluating the connections between the evidence and the statement.
- These arguments are defeasible, meaning that their conclusions can be accepted only provisionally while there is no evidence that defeats it.

- **LLM BAD habits:**
  - (a) the introduction of new concepts or topics
  - (b) bad reasoning, namely, questions critical towards positions or claims the speaker does not hold
  - (c) non-specific critical questions that could be asked on any argument and that do not take the intervention into account.

-  unmasking a blind spot in the argument: We operationalized this evaluation by taking each argument and question pairs and asking: "Can the answer to this question diminish the acceptability of the argument?" - answer is yes or no.

- Theory-CQ:
  - asking about the relation between the premises and the conclusion (27%), 
  - followed by questions about the available evidence (24%),
  -  and questions about possible exceptions (18%). 
  
- llm-CQs, 
  - asking about evidence is the most common type of CQs (27%),
  - followed by relations (21%) and 
  - potential consequences of the premises (17%). 
  - Most interestingly, we find that 16% of llm-CQs are asking for more specific definitions of the concepts present in the argument. This kind of questions are not contemplated at all in the theoretical sets of questions, and both of our annotators considered them valid (the first llm-CQ in Figure 3 is of this type). Finally, the few questions that are generated with both approaches (theory and LLMs) are mostly about consequences and evidence

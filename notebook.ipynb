{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Task: Critical thinking generation\n",
    "## Loadind Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 42027.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLINTON_1_1\n",
      "CLINTON: \"The central question in this election is really what kind of country we want to be and what kind of future we 'll build together\n",
      "Today is my granddaughter 's second birthday\n",
      "I think about this a lot\n",
      "we have to build an economy that works for everyone , not just those at the top\n",
      "we need new jobs , good jobs , with rising incomes\n",
      "I want us to invest in you\n",
      "I want us to invest in your future\n",
      "jobs in infrastructure , in advanced manufacturing , innovation and technology , clean , renewable energy , and small business\n",
      "most of the new jobs will come from small business\n",
      "We also have to make the economy fairer\n",
      "That starts with raising the national minimum wage and also guarantee , finally , equal pay for women 's work\n",
      "I also want to see more companies do profit-sharing\"\n",
      "--------------------------------------------------\n",
      "Javier_84\n",
      "Javier: \"I have no problem requiring the airlines to give notification of any \"known\" delays within 30 minutes of when they become aware of it.\n",
      "BUT, being a frequent traveler, I see all sorts of problems which are unavoidable and for which the airlines will be blamed by giving such notice with the intend that some flyers may be able to delay thier trip to the airport or even the departure gate.\n",
      "I know that many times the airlines can't also know exactly when a weather hold or a maintenance issue will be rectified and that the flight is then ready to go.\n",
      "Many time it can be surprisingly faster than expected.\n",
      "The problem is that some flyers may then  wait before going to the airport,\n",
      "but then find that the problem was rectified sooner than expected and the flight departed.\n",
      "Of course the flyer and the flyers rights organization will then crucify the airlines for such poor planning.\n",
      "Flyers need to grow up and quit pouting and blaming everthing on the airlines.\n",
      "They can't have it both ways.\"\n",
      "--------------------------------------------------\n",
      "TRUMP_125_1\n",
      "TRUMP: \"Secretary Clinton doesn't want to use a couple of words, and that's law and order\n",
      "If we don't have it, we're not going to have a country\n",
      "when I look at what's going on in Charlotte, a city I love, a city where I have investments, when I look at what's going on throughout various parts of our country, whether it's—I mean, I can just keep naming them all day long\n",
      "I just got today the, as you know, the endorsement of the Fraternal Order of Police, we just—just came in\n",
      "We have endorsements from, I think, almost every police group, very—I mean, a large percentage of them in the United States\n",
      "We have a situation where we have our inner cities, African- Americans, Hispanics are living in hell\n",
      "it's so dangerous\n",
      "You walk down the street, you get shot\n",
      "In Chicago, they've had thousands of shootings, thousands since January 1st\n",
      "I'm saying, where is this\n",
      "Is this a war-torn country\n",
      "What are we doing\n",
      "we have to stop the violence\n",
      "In a place like Chicago, where thousands of people have been killed, thousands over the last number of years\n",
      "almost 4,000 have been killed since Barack Obama became president\"\n",
      "--------------------------------------------------\n",
      "travellots_133_1\n",
      "travellots: \"There should be no discrimination in how a passenger is bumped or compensated just because they may have paid less for a ticket or used frequent flyer miles.\n",
      "Airline tickets are not lottery tickets.\n",
      "One does not purchase a ticket hoping to reach a certain destination.\n",
      "Same as if one pays $4 for a cup of coffee or $1, the cup is supposed to have coffee in it.\n",
      "The price does not dictate that \"maybe\" you will get the product or service.\n",
      "Also, the airline decides what prices or miles are used to purchase a promise to get you from point A to point B.\n",
      "If they can not afford to give  a ticket for that price, they should not sell it.\n",
      "When you reserve a ticket, the assumption is that you will be taken from point A to point B by the times given by the airline.\n",
      "A passenger does not purchase a ticket just to see if maybe they can get somewhere because they have nothing better to do.\"\n",
      "--------------------------------------------------\n",
      "Zewstain__641\n",
      "Zewstain: \"It seemed like that was most of her argument. Being a woman\n",
      "How will you differ from Obama? Hillary: As a woman it's clear. Cooper: Any policy differences? Hillary: Hello, I'm a woman\"\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "# Reading the data\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_st_data(name : str = \"validation\"):\n",
    "    with open(f'data_splits/{name}.json') as f:\n",
    "        dataset=json.load(f)\n",
    "        return dataset\n",
    "\n",
    "for key, line in tqdm.tqdm(get_st_data(\"sample\").items()):\n",
    "    print(key)\n",
    "\n",
    "    print(line['intervention'])\n",
    "    input_text = line['intervention']\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from helper.custom_lllm import CustomLLM\n",
    "import pandas as pd\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os, getpass\n",
    "\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import operator\n",
    "from typing import  Annotated\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "env, LLM, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "_set_env(\"MISTRAL_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"shared_task_critical_questions\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"o3-mini\"\n",
    "# temperature = 0 not for o3-mini\n",
    "temperature = \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EXPERIMENT_NAME = f\"{model_name}_temperature{temperature}\"\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=model_name, temperature=None) \n",
    "\n",
    "# model_api = ChatMistralAI(model=\"open-mistral-7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Workflow\n",
    "####  1. Zero Shot LLM to start with..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 38 (graph_tools.py, line 38)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniforge3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[26], line 2\u001b[0;36m\n\u001b[0;31m    from my_models.graph_tools import build_zero_shot_graph\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Documents/projects/github/shared_task_cq_submission/my_models/graph_tools.py:38\u001b[0;36m\u001b[0m\n\u001b[0;31m    def evaluate(data_split: str = \"validation\"):\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 38\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from my_models.graph_tools import build_zero_shot_graph\n",
    "# memory = MemorySaver()\n",
    "graph =build_zero_shot_graph(llm) #interrupt_before=['human_feedback'], checkpointer=memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def timer(label: str):\n",
    "    start = time.perf_counter()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        end = time.perf_counter()\n",
    "        print(f\"{label}: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iteration</th>\n",
       "      <th>time_o3-mini_temperatureNA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.7111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.3274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.8122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.7671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>5.6682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>182</td>\n",
       "      <td>5.9174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>183</td>\n",
       "      <td>6.4663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>184</td>\n",
       "      <td>4.0835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>185</td>\n",
       "      <td>6.6877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iteration time_o3-mini_temperatureNA\n",
       "0            0                     4.7111\n",
       "1            1                     7.0396\n",
       "2            2                     7.3274\n",
       "3            3                     4.8122\n",
       "4            4                     5.7671\n",
       "..         ...                        ...\n",
       "181        181                     5.6682\n",
       "182        182                     5.9174\n",
       "183        183                     6.4663\n",
       "184        184                     4.0835\n",
       "185        185                     6.6877\n",
       "\n",
       "[186 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def _invoke_graph(params, thread= None):\n",
    "    questions = []\n",
    "    for event in graph.stream(params, thread, stream_mode=\"values\"):\n",
    "        # Review\n",
    "        _labels = event.get('critical_question_list', '')\n",
    "        if _labels:  \n",
    "            questions.append(_labels)\n",
    "    assert len(questions) == 1\n",
    "    return questions[0]\n",
    "\n",
    "\n",
    "def run( data_type: str = \"validation\", experiment_name: str = \"\", save: bool = True):\n",
    "    out = {}\n",
    "    for _,line in tqdm.tqdm(get_st_data(data_type).items()):\n",
    "        with timer(f\"Iteration {line['intervention_id']}\"):\n",
    "            input_arg = line['intervention']\n",
    "            cqs = _invoke_graph({\"input_arg\": input_arg}).model_dump()['critical_questions']        \n",
    "        \n",
    "            for e in cqs:\n",
    "                e[\"cq\"] = e.pop(\"critical_question\")\n",
    "            line['cqs'] = cqs\n",
    "\n",
    "            out[line['intervention_id']]=line\n",
    "    if save:\n",
    "        with open(f'output/output_{experiment_name}.json', 'w') as o:\n",
    "            json.dump(out, o, indent=4)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# 17 min 28.4 seconds for 186 entries on o3-mini\n",
    "\n",
    "import re\n",
    "\n",
    "# Read the entire file content\n",
    "with open('my_folder/timelogs_0shot_o3mini.txt', 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "# Use regex to extract numbers after the colon and before \"seconds\"\n",
    "numbers = re.findall(r'Iteration\\s+\\S+:\\s+([\\d.]+)\\s+seconds', data)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(list(enumerate(numbers)), columns=[\"Iteration\", f\"time_{EXPERIMENT_NAME}\"])\n",
    "df[f\"time_{EXPERIMENT_NAME}\"] = pd.to_numeric(df[f\"time_{EXPERIMENT_NAME}\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "### Run shell \n",
    "\n",
    "```shell\n",
    "\n",
    "python3 eval_scripts/evaluation.py \\\n",
    "    --metric similarity \\\n",
    "    --input_path data_splits/validation.json \\\n",
    "    --submission_path output/output_o3-mini_temperatureNA.json \\\n",
    "    --threshold 0.6 \n",
    "\n",
    "```\n",
    "\n",
    "#### OUTPUT : output/output_o3-mini_temperatureNA._eval_similarity_06.json\n",
    "\n",
    "\n",
    "\n",
    "#### Overall count\n",
    "\n",
    "| **Questions Labels** |  **#**  | **ratio** |\n",
    "|:--------------------|-------:|---------:|\n",
    "| useful               | **329** |  **0,59** |\n",
    "| unhelpful            |      63 |      0,11 |\n",
    "| Invalid              |       8 |      0,01 |\n",
    "| Not able to evaluate |     158 |      0,28 |\n",
    "| **Total**            | **558** |         1 |\n",
    "\n",
    "\n",
    "#### Within argument \n",
    "\n",
    "| **n/3 useful questions per arg** | **# of arguments** | **ratio** |\n",
    "|:-------------------------------:|-------------------:|:---------:|\n",
    "|                               0/3 |                 17 |      0,10 |\n",
    "|                               1/3 |                 51 |      0,27 |\n",
    "|                               2/3 |             **76** |      0,40 |\n",
    "|                               3/3 |                 42 |      0,23 |\n",
    "| **Total**                       |            **186** |         1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

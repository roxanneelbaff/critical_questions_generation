{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Task: Critical thinking generation\n",
    "## Loadind Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q social_agents/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show social_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import social_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLINTON_1_1\n",
      "CLINTON: \"The central question in this election is really what kind of country we want to be and what kind of future we 'll build together\n",
      "Today is my granddaughter 's second birthday\n",
      "I think about this a lot\n",
      "we have to build an economy that works for everyone , not just those at the top\n",
      "we need new jobs , good jobs , with rising incomes\n",
      "I want us to invest in you\n",
      "I want us to invest in your future\n",
      "jobs in infrastructure , in advanced manufacturing , innovation and technology , clean , renewable energy , and small business\n",
      "most of the new jobs will come from small business\n",
      "We also have to make the economy fairer\n",
      "That starts with raising the national minimum wage and also guarantee , finally , equal pay for women 's work\n",
      "I also want to see more companies do profit-sharing\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "# Reading the data\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from social_agents.utils import get_st_data\n",
    "\n",
    "\n",
    "for key, line in tqdm.tqdm(get_st_data(\"sample\").items()):\n",
    "    print(key)\n",
    "\n",
    "    print(line['intervention'])\n",
    "    input_text = line['intervention']\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import os, getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "env, LLM, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "_set_env(\"MISTRAL_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"shared_task_critical_questions\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature = 0 not for o3-mini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Zero Shot LLM to start with o3-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from social_agents.graph_tools import BasicCQModel\n",
    "model_name = \"o3-mini\"\n",
    "\n",
    "basic_agent = BasicCQModel(llm_name = model_name, temperature=None ) #interrupt_before=['human_feedback'], checkpointer=memory)\n",
    "\n",
    "\n",
    "display(Image(basic_agent.graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "\n",
    "# RUN\n",
    "# basic_agent.run_experiment()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "### Evaulate \n",
    "\n",
    "- Run shell \n",
    "\n",
    "```shell\n",
    "\n",
    "python3 eval_scripts/evaluation.py \\\n",
    "    --metric similarity \\\n",
    "    --input_path data_splits/validation.json \\\n",
    "    --submission_path output/output_o3-mini_temperatureNA.json \\\n",
    "    --threshold 0.6 \n",
    "\n",
    "```\n",
    "\n",
    "- OUTPUT : output/output_o3-mini_temperatureNA._eval_similarity_06.json\n",
    "\n",
    "\n",
    "\n",
    "**Overall count**\n",
    "\n",
    "| **Questions Labels** |  **#**  | **ratio** |\n",
    "|:--------------------|-------:|---------:|\n",
    "| useful               | **329** |  **0,59** |\n",
    "| unhelpful            |      63 |      0,11 |\n",
    "| Invalid              |       8 |      0,01 |\n",
    "| Not able to evaluate |     158 |      0,28 |\n",
    "| **Total**            | **558** |         1 |\n",
    "\n",
    "\n",
    "**Overall count within each argument**\n",
    "\n",
    "| **n/3 useful questions per arg** | **# of arguments** | **ratio** |\n",
    "|:-------------------------------:|-------------------:|:---------:|\n",
    "|                               0/3 |                 17 |      0,10 |\n",
    "|                               1/3 |                 51 |      0,27 |\n",
    "|                               2/3 |             **76** |      0,40 |\n",
    "|                               3/3 |                 42 |      0,23 |\n",
    "| **Total**                       |            **186** |         1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from typing import Dict, Literal, TypedDict\n",
    "\n",
    "from social_agents.graph_tools import CQSTAbstractAgent\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from social_agents.objects import  CriticalQuestionList\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "class Confirmation(BaseModel):\n",
    "    confirmation: str = Field(\n",
    "        description=\"The LLM confirms the role assigned to it by simply saying ok.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class SocialAgentAnswer(BaseModel):\n",
    "    critical_question_list: CriticalQuestionList = Field(\n",
    "        description=\"The list of all the critical questions and their ranks to criticize and reveal the weaknesses of an argument.\"\n",
    "    )\n",
    "    question_type: Literal[\"debate\", \"reflect\", \"question\"]\n",
    "    prompt: str\n",
    "\n",
    "\n",
    "class SocialAgentState(TypedDict):\n",
    "    input_arg: str\n",
    "    current_round: int = -1  # 1:start\n",
    "    collaborative_strategy: list\n",
    "\n",
    "    round_answer_dict: dict[str, list[SocialAgentAnswer]] = dataclasses.field(\n",
    "        default_factory=dict\n",
    "    )  # key is agent and value array of N CriticalQuestionList (based on number of rounds)\n",
    "\n",
    "    # OutPut\n",
    "    final_cq: CriticalQuestionList\n",
    "\n",
    "\n",
    "# @dataclasses.dataclass\n",
    "# class SocialAgentsModel(CQSTAbstractAgent):\n",
    "collaborative_strategy = [\"debate\", \"reflect\", \"debate\"]\n",
    "agent_trait_lst: list = [\"easy_going\", \"overconfident\", \"easy_going\"]\n",
    "llm_name = \"o3-mini-2025-01-31\"\n",
    "temperature = 0.0\n",
    "llm_lst = [\n",
    "    CQSTAbstractAgent._init_llm(llm_name, temperature)\n",
    "    for _ in range(len(agent_trait_lst))\n",
    "]\n",
    "validator_llm = CQSTAbstractAgent._init_llm(llm_name, temperature)\n",
    "\n",
    "\n",
    "def llm_role_node(state: SocialAgentState):\n",
    "    are_all_roles_confirmed = True\n",
    "    for i, llm in enumerate(llm_lst):\n",
    "        structured_llm = llm.with_structured_output(Confirmation)\n",
    "        with open(f\"prompts/trait_{agent_trait_lst[i]}.txt\", \"r\") as f:\n",
    "            trait_prompt = f.read()\n",
    "\n",
    "        response = structured_llm.invoke(\n",
    "            trait_prompt\n",
    "        )\n",
    "        if response.confirmation.lower() == \"ok\":\n",
    "            print(\"role confirmed\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"Unconfirmed Role: {response.confirmation}\")\n",
    "            are_all_roles_confirmed = False\n",
    "            break\n",
    "            \n",
    "    return {\"role_confirmed\": are_all_roles_confirmed,\n",
    "            \"current_round\": -1}\n",
    "\n",
    "def is_role_confirmed(state):\n",
    "    if state[\"role_confirmed\"]:\n",
    "        return \"question_node\"\n",
    "    else: return END\n",
    "\n",
    "def question_node(state: SocialAgentState):\n",
    "    round_answer_dict = {}\n",
    "    for i, llm in enumerate(llm_lst):\n",
    "        structured_llm = llm.with_structured_output(CriticalQuestionList)\n",
    "        # with open(\"prompts/system.txt\", \"r\") as f:\n",
    "        #    system_prompt = f.read()\n",
    "        with open(\"prompts/question.txt\", \"r\") as file:\n",
    "            instructions = file.read()\n",
    "\n",
    "        instructions = instructions.format(\n",
    "            input_arg=state[\"input_arg\"],\n",
    "        )\n",
    "        response = structured_llm.invoke(instructions)\n",
    "        answer: SocialAgentAnswer = SocialAgentAnswer(\n",
    "            critical_question_list=response,\n",
    "            question_type=\"question\",\n",
    "            prompt=instructions,\n",
    "        )\n",
    "        \n",
    "        print(1)\n",
    "        round_answer_dict[f\"agent{i}\"] = [answer]\n",
    "        print(2)\n",
    "        print(3)\n",
    "\n",
    "    return {\"current_round\": state[\"current_round\"] + 1,\n",
    "        \"round_answer_dict\":round_answer_dict }\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def debate_node(state: SocialAgentState):\n",
    "    for i, llm in enumerate(llm_lst):\n",
    "        structured_llm = llm.with_structured_output(CriticalQuestionList)\n",
    "\n",
    "        with open(\"prompts/strategy_debate.txt\", \"r\") as file:\n",
    "            instructions = file.read()\n",
    "\n",
    "        # Get others answer\n",
    "        round_answer_dict = state[\"round_answer_dict\"]\n",
    "        print(round_answer_dict)\n",
    "        others_answers = [\n",
    "            round_answer_dict[f\"agent{x}\"][-1] for x, _ in enumerate(llm_lst) if x != i\n",
    "        ]\n",
    "\n",
    "        other_agents_response_str = \"\"\n",
    "        other_cq_str = \"\\n- critical question {id}: '{cq}', reasoning: '{reason}'.\\n\"\n",
    "        for a_num, other_ in enumerate(others_answers):\n",
    "            other_agents_response_str += f\"Agent{a_num+1}:\"\n",
    "            for cq in other_.critical_question_list.critical_questions:\n",
    "                other_agents_response_str = (\n",
    "                    other_agents_response_str\n",
    "                    + other_cq_str.format(id = cq.id, cq=cq.critical_question, reason=cq.reason)\n",
    "                )\n",
    "            other_agents_response_str += \"\\n\\n\"\n",
    "\n",
    "        instructions = instructions.format(\n",
    "            input_arg=state[\"input_arg\"],\n",
    "            other_agents_response=other_agents_response_str,\n",
    "        )\n",
    "\n",
    "        response = structured_llm.invoke(instructions)\n",
    "        answer: SocialAgentAnswer = SocialAgentAnswer(\n",
    "            critical_question_list=response,\n",
    "            question_type=\"debate\",\n",
    "            prompt=instructions,\n",
    "        )\n",
    "\n",
    "        round_answer_dict[f\"agent{i}\"].append(answer)\n",
    "        state[\"round_answer_dict\"] = round_answer_dict\n",
    "\n",
    "    \n",
    "    return {\"current_round\": state[\"current_round\"] + 1,\n",
    "            \"round_answer_dict\":round_answer_dict }\n",
    "    \n",
    "    \n",
    "    \n",
    "def decide_next(state) -> Literal[\"debate\", \"reflect\", \"validate\"]:\n",
    "    if len(state[\"collaborative_strategy\"]) > state[\"current_round\"]:\n",
    "        print(f'MOVING TO STATE {state[\"collaborative_strategy\"][state[\"current_round\"]]}')\n",
    "        return f'{state[\"collaborative_strategy\"][state[\"current_round\"]]}_node'\n",
    "    else:\n",
    "        print(\"going to validate node\")\n",
    "        return \"validate_node\"\n",
    "\n",
    "\n",
    "\n",
    "def reflect_node(state: SocialAgentState):\n",
    "    for i, llm in enumerate(llm_lst):\n",
    "        structured_llm = llm.with_structured_output(CriticalQuestionList)\n",
    "\n",
    "        with open(\"prompts/strategy_reflect.txt\", \"r\") as file:\n",
    "            instructions = file.read()\n",
    "\n",
    "        # Get others answer\n",
    "        round_answer_dict = state[\"round_answer_dict\"]\n",
    "        previous_answer = round_answer_dict[f\"agent{i}\"][-1]\n",
    "        instructions = instructions.format(\n",
    "            input_arg=state[\"input_arg\"], previous_answer=previous_answer\n",
    "        )\n",
    "\n",
    "        response = structured_llm.invoke(instructions)\n",
    "        answer: SocialAgentAnswer = SocialAgentAnswer(\n",
    "            critical_question_list=response,\n",
    "            question_type=\"debate\",\n",
    "            prompt=instructions,\n",
    "        )\n",
    "\n",
    "        round_answer_dict[f\"agent{i}\"].append(answer)\n",
    "        state[\"round_answer_dict\"] = round_answer_dict\n",
    "    return {\"current_round\": state[\"current_round\"] + 1,\n",
    "        \"round_answer_dict\":round_answer_dict }\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def validate_node(state: SocialAgentState):\n",
    "    structured_llm = validator_llm.with_structured_output(CriticalQuestionList)\n",
    "    with open(\"prompts/validator.txt\", \"r\") as file:\n",
    "        instructions = file.read()\n",
    "    # Get others answer\n",
    "    round_answer_dict = state[\"round_answer_dict\"]\n",
    "    others_answers = [\n",
    "        round_answer_dict[f\"agent{x}\"][-1] for x, _ in enumerate(llm_lst)\n",
    "    ]\n",
    "    other_agents_response_str = \"\"\n",
    "    other_cq_str = \"\\n- critical question {id}: '{cq}'.\\n\" # reasoning: '{reason}'\n",
    "    for a_num, other_ in enumerate(others_answers):\n",
    "        other_agents_response_str += f\"Agent{a_num+1}:\"\n",
    "        for cq in other_.critical_question_list.critical_questions:\n",
    "            other_agents_response_str = (\n",
    "                other_agents_response_str\n",
    "                + other_cq_str.format(id = cq.id, cq=cq.critical_question, reason=cq.reason)\n",
    "            )\n",
    "        other_agents_response_str += \"\\n\\n\"\n",
    "    instructions = instructions.format(\n",
    "        input_arg=state[\"input_arg\"],\n",
    "        other_agents_response=other_agents_response_str,\n",
    "    )\n",
    "    response = structured_llm.invoke(instructions)\n",
    "    print(instructions)\n",
    "    return {\"final_cq\": response}\n",
    "\n",
    "\n",
    "\n",
    "builder = StateGraph(SocialAgentState)\n",
    "\n",
    "builder.add_node(\"llm_role_node\", llm_role_node)\n",
    "builder.add_node(\"question_node\", question_node)\n",
    "builder.add_node(\"debate_node\", debate_node)\n",
    "builder.add_node(\"reflect_node\", reflect_node)\n",
    "builder.add_node(\"validate_node\", validate_node)\n",
    "\n",
    "builder.add_edge(START, \"llm_role_node\")\n",
    "builder.add_edge(\"llm_role_node\", \"question_node\")\n",
    "builder.add_conditional_edges(\"question_node\", decide_next, [\"debate_node\", \"reflect_node\", \"validate_node\"])\n",
    "builder.add_conditional_edges(\"debate_node\", decide_next, [\"debate_node\", \"reflect_node\", \"validate_node\"])\n",
    "builder.add_conditional_edges(\"reflect_node\", decide_next, [\"debate_node\", \"reflect_node\", \"validate_node\"])\n",
    "builder.add_edge(\"validate_node\", END)\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langchain_core.runnables.graph import CurveStyle\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile( checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role confirmed\n",
      "role confirmed\n",
      "role confirmed\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "thread_id = uuid.uuid4()\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "graph.invoke({\"collaborative_strategy\": collaborative_strategy, \"input_arg\": \"I am human therefore I am mortal\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png(curve_style=CurveStyle.LINEAR, padding=0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

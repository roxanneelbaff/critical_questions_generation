{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Task: Critical thinking generation\n",
    "## Loadind Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q social_agents/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show social_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "# Reading the data\n",
    "import json\n",
    "import pandas as pd\n",
    "import social_agents\n",
    "\n",
    "from social_agents.utils import get_st_data\n",
    "\n",
    "\n",
    "for key, line in tqdm.tqdm(get_st_data(\"sample\").items()):\n",
    "    print(key)\n",
    "\n",
    "    print(line['intervention'])\n",
    "    input_text = line['intervention']\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "env, LLM, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "_set_env(\"MISTRAL_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"shared_task_critical_questions\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Zero Shot LLM to start with o3-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from social_agents.graph_tools import BasicCQModel\n",
    "model_name = \"o3-mini\"\n",
    "\n",
    "basic_agent = BasicCQModel(llm_name = model_name, temperature=None ) #interrupt_before=['human_feedback'], checkpointer=memory)\n",
    "\n",
    "\n",
    "display(Image(basic_agent.graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "\n",
    "# RUN\n",
    "# basic_agent.run_experiment()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "### Evaulate \n",
    "\n",
    "- Run shell \n",
    "\n",
    "```shell\n",
    "\n",
    "python3 eval_scripts/evaluation.py \\\n",
    "    --metric similarity \\\n",
    "    --input_path data_splits/validation.json \\\n",
    "    --submission_path output/output_o3-mini_temperatureNA.json \\\n",
    "    --threshold 0.6 \n",
    "\n",
    "```\n",
    "\n",
    "- OUTPUT : output/output_o3-mini_temperatureNA._eval_similarity_06.json\n",
    "\n",
    "\n",
    "\n",
    "**Overall count**\n",
    "\n",
    "| **Questions Labels** |  **#**  | **ratio** |\n",
    "|:--------------------|-------:|---------:|\n",
    "| useful               | **329** |  **0,59** |\n",
    "| unhelpful            |      63 |      0,11 |\n",
    "| Invalid              |       8 |      0,01 |\n",
    "| Not able to evaluate |     158 |      0,28 |\n",
    "| **Total**            | **558** |         1 |\n",
    "\n",
    "\n",
    "**Overall count within each argument**\n",
    "\n",
    "| **n/3 useful questions per arg** | **# of arguments** | **ratio** |\n",
    "|:-------------------------------:|-------------------:|:---------:|\n",
    "|                               0/3 |                 17 |      0,10 |\n",
    "|                               1/3 |                 51 |      0,27 |\n",
    "|                               2/3 |             **76** |      0,40 |\n",
    "|                               3/3 |                 42 |      0,23 |\n",
    "| **Total**                       |            **186** |         1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "EXPERIMENT_SETTINGS_FILE_PATH = \"output/elbaff_experiment/experiment_settings.csv\"\n",
    "experiment_settings = pd.read_csv(EXPERIMENT_SETTINGS_FILE_PATH)\n",
    "\n",
    "\n",
    "llm_name = \"gpt-4o-mini-2024-07-18\"# \"o3-mini-2025-01-31\"\n",
    "temperature = 0.7\n",
    "\n",
    "exp_row = experiment_settings.iloc[9].to_dict()\n",
    "exp_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "exp_row[\"experiment_name\"].format(llm_name= llm_name)\n",
    "\n",
    "list(ast.literal_eval(exp_row[\"traits\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ast\n",
    "from social_agents import objects\n",
    "from social_agents.graph_tools import  CQSTAbstractAgent, SocialAgentBuilder\n",
    "import json \n",
    "\n",
    "#for _, exp_row in experiment_settings.items():\n",
    "\n",
    "social_agent = SocialAgentBuilder(\n",
    "    model_thread_id=exp_row[\"thread_id\"],\n",
    "    llm_name = llm_name,\n",
    "    llm_num = exp_row[\"number_of_agents\"],\n",
    "    experiment_name= exp_row[\"experiment_name\"].format(llm_name= llm_name),\n",
    "    temperature=temperature,\n",
    "    collaborative_strategy=list(ast.literal_eval(exp_row[\"strategies\"])),\n",
    "    agent_trait_lst=list(ast.literal_eval(exp_row[\"traits\"])))\n",
    "\n",
    "id_= \"123\"\n",
    "params = {\"input_arg\": \"To be or not to be this is the question. Is it?\"}\n",
    "\n",
    "questions = []\n",
    "id_ = \"123\"\n",
    "config = {\"configurable\": {\"thread_id\": f\"{social_agent.model_thread_id}_{id_}\"}}\n",
    "\n",
    "params = {\n",
    "    \"input_arg\": \"To be or not to be this is the question. Is it?\",\n",
    "}\n",
    "\n",
    "for event in social_agent.graph.stream(params, config=config, stream_mode=\"values\"):\n",
    "    # Review\n",
    "    _labels = event.get(\"final_cq\", \"\")\n",
    "    if _labels:\n",
    "        questions.append(_labels)\n",
    "        # Save the final state\n",
    "        with open(f\"{CQSTAbstractAgent.ROOT_FOLDER}{social_agent.experiment_name}_arg{id_}.json\", \"w\") as f:\n",
    "          json.dump(objects.state_to_serializable(event), f,indent=2)\n",
    "        break\n",
    "assert len(questions) == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from social_agents import objects\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "my_list = [\"debate\", \"debate\", \"reflect\"]\n",
    "counts = Counter(my_list)\n",
    "print(counts)        # Output: Counter({2: 3, 1: 1, 3: 1, 4: 1, 5: 1})\n",
    "print(counts[\"debate\"])     # Output: 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"configurable\": {\"thread_id\": f\"{social_agent.model_thread_id}_{id_}\"}}.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_obj = social_agent.graph.get_graph(xray=1)\n",
    "mermaid_code = graph_obj.draw_mermaid()  # Get the textual diagram\n",
    "print(mermaid_code)\n",
    "display(Image(social_agent.graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(social_agent.graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_invoke_graph(params, id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = app.invoke({\"collaborative_strategy\": collaborative_strategy, \"input_arg\": \"I am human therefore I am mortal\"}, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

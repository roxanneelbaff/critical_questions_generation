{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q social_agents/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show social_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U pydantic\n",
    "%pip install -U \"langchain[together]\"\n",
    "%pip install -U \"langchain\"\n",
    "%pip install -U \"langgraph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "# Reading the data\n",
    "import pandas as pd\n",
    "\n",
    "from social_agents.utils import get_st_data\n",
    "\n",
    "\n",
    "for key, line in tqdm.tqdm(get_st_data(\"sample\").items()):\n",
    "    print(key)\n",
    "\n",
    "    print(line['intervention'])\n",
    "    input_text = line['intervention']\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "env, LLM, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Task: Critical thinking generation\n",
    "## Loadind Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "from langchain.chat_models import init_chat_model\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "_set_env(\"MISTRAL_API_KEY\")\n",
    "_set_env(\"TOGETHER_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"shared_task_critical_questions\"\n",
    "\n",
    "#init_chat_model(\"meta-llama/Llama-3.2-3B-Instruct-Turbo\", model_provider=\"together\", temperature= 0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#llm_name = \"gpt-4o-mini-2024-07-18\"# \"o3-mini-2025-01-31\"\n",
    "#llm_name_short = \"gpt-4o-mini_\"\n",
    "llm_dic = {\n",
    "    #\"openai_o3mini\": \"o3-mini-2025-01-31\",\n",
    "    #\"gpt-4o-mini_\": \"gpt-4o-mini-2024-07-18\",\n",
    "    \"llama8b_\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "    \"mistral24b_\": \"mistral-small-2503\",#\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    \"llama70b_\": \"meta-llama/Llama-3.3-70B-Instruct-Turbo\"\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Zero Shot LLM to start with o3-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/186 [00:41<18:22,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Elmattador__92: 20.2757 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 24/186 [00:42<13:31,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration FoodAllergyMom_199_1: 0.9198 seconds\n",
      "Exception repeat 1\n",
      "Exception repeat 2\n",
      "Exception repeat 3\n",
      "Exception repeat 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 25/186 [00:46<12:35,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Frequent-Flyer_157: 3.9582 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 26/186 [00:46<09:22,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Glblwrmingisfak__552: 0.7742 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 27/186 [00:47<07:11,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration HOLT_126: 0.8382 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 28/186 [00:48<05:41,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration HOLT_239: 0.8779 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 29/186 [00:49<04:31,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration HOLT_94: 0.7160 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 30/186 [00:50<03:47,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Helen__66: 0.8190 seconds\n",
      "Exception repeat 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 31/186 [00:52<04:32,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17th_knight__247: 2.4579 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 32/186 [00:53<04:01,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration AFCHF_154: 1.1266 seconds\n",
      "Exception repeat 1\n",
      "Exception repeat 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 33/186 [00:56<04:40,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration AK-traveler_186: 2.4564 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 34/186 [00:57<03:57,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration AllergyDad_200: 0.9247 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 35/186 [00:57<03:26,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration AngelComa__638: 0.9169 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 36/186 [00:59<03:09,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Antanagoge_104: 1.0235 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 37/186 [01:00<03:03,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Antanagoge_111: 1.1418 seconds\n",
      "Exception repeat 1\n",
      "Exception repeat 2\n",
      "Exception repeat 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 38/186 [01:23<19:23,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Antanagoge_227: 23.3346 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 39/186 [01:43<28:24, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Antanagoge_239: 20.3133 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 40/186 [01:44<20:23,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Bill_106: 0.8777 seconds\n",
      "Exception repeat 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 41/186 [01:46<15:35,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration CF_29: 1.9488 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 42/186 [01:47<11:30,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration CF_46: 0.9231 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 43/186 [01:48<08:39,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration CLINTON_103: 0.9187 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 44/186 [01:49<06:35,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration CLINTON_123_1: 0.8189 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 45/186 [01:50<05:05,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration CLINTON_123_2: 0.7120 seconds\n",
      "Exception repeat 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 46/186 [01:52<05:06,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration CLINTON_130_1: 2.2540 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 47/186 [01:53<04:33,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration CLINTON_130_2: 1.4382 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 48/186 [01:54<03:51,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration CLINTON_147: 0.9940 seconds\n",
      "Exception repeat 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 49/186 [01:56<03:49,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration CLINTON_17: 1.6796 seconds\n",
      "Exception repeat 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 50/186 [01:57<03:31,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration CLINTON_176_1: 1.2792 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 51/186 [01:58<03:01,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration CLINTON_176_2: 0.8544 seconds\n",
      "Exception repeat 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 52/186 [02:00<03:36,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration CLINTON_186: 2.2491 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 53/186 [02:01<03:03,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration CLINTON_193: 0.8164 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 54/186 [02:02<02:35,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration CLINTON_199_1: 0.7162 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 55/186 [02:03<02:20,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration TRUMP_240_2: 0.8213 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 56/186 [02:04<02:21,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration TRUMP_249: 1.1257 seconds\n",
      "Exception repeat 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from social_agents.agent_builder import BasicCQModel\n",
    "\n",
    "\n",
    "for llm_key, llm_full in llm_dic.items():\n",
    "    print(f\"Running {llm_key}\")\n",
    "    basic_agent = BasicCQModel(\n",
    "        model_thread_id=f\"{llm_key}_zero-shot\",\n",
    "        llm_name = llm_full,\n",
    "        llm_num = 1,\n",
    "        experiment_name= f\"{llm_key}_zero-shot\",\n",
    "        temperature=0.7)\n",
    "        \n",
    "        \n",
    "    display(Image(basic_agent.graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "\n",
    "# RUN\n",
    "    basic_agent.run_experiment()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "### Evaulate \n",
    "\n",
    "- Run shell \n",
    "\n",
    "```shell\n",
    "\n",
    "python3 eval_scripts/evaluation.py \\\n",
    "    --metric similarity \\\n",
    "    --input_path data_splits/validation.json \\\n",
    "    --submission_path output/elbaff_experiment/output_gpt-4o-mini-2024-07-18social_n2_Te_Sr.json \\\n",
    "    --threshold 0.6 \n",
    "\n",
    "```\n",
    "\n",
    "- OUTPUT : output/output_o3-mini_temperatureNA._eval_similarity_06.json\n",
    "\n",
    "\n",
    "\n",
    "**Overall count**\n",
    "\n",
    "| **Questions Labels** |  **#**  | **ratio** |\n",
    "|:--------------------|-------:|---------:|\n",
    "| useful               | **329** |  **0,59** |\n",
    "| unhelpful            |      63 |      0,11 |\n",
    "| Invalid              |       8 |      0,01 |\n",
    "| Not able to evaluate |     158 |      0,28 |\n",
    "| **Total**            | **558** |         1 |\n",
    "\n",
    "\n",
    "**Overall count within each argument**\n",
    "\n",
    "| **n/3 useful questions per arg** | **# of arguments** | **ratio** |\n",
    "|:-------------------------------:|-------------------:|:---------:|\n",
    "|                               0/3 |                 17 |      0,10 |\n",
    "|                               1/3 |                 51 |      0,27 |\n",
    "|                               2/3 |             **76** |      0,40 |\n",
    "|                               3/3 |                 42 |      0,23 |\n",
    "| **Total**                       |            **186** |         1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from social_agents import helper\n",
    "from social_agents.agent_builder import   SocialAgentBuilder\n",
    "\n",
    "EXPERIMENT_SETTINGS_FILE_PATH = \"output/elbaff_experiment/experiment_settings.csv\"\n",
    "override = False\n",
    "if not os.path.exists(EXPERIMENT_SETTINGS_FILE_PATH) or override:\n",
    "    print(\"generating exp settings file\")\n",
    "    exps_df = helper.generate_experiment_settings()\n",
    "    exps_df.to_csv(EXPERIMENT_SETTINGS_FILE_PATH, index=False)\n",
    "\n",
    "experiment_settings = pd.read_csv(EXPERIMENT_SETTINGS_FILE_PATH)\n",
    "experiment_settings.head()\n",
    "\n",
    "# exp_row = experiment_settings.iloc[20].to_dict()\n",
    "# exp_row\n",
    "experiment_settings = experiment_settings.sort_values(by=[\"rounds\", \"number_of_agents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import time\n",
    "from social_agents import data_model\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "temperature = 0.7\n",
    "llm_name_short = \"mistral24b_\"\n",
    "llm_name = llm_dic[llm_name_short]\n",
    "def run_all_exp_settings(experiment_settings):\n",
    "    all_done = False\n",
    "    for _, row in tqdm(experiment_settings.iterrows(), total=len(experiment_settings)):\n",
    "        exp_name = row[\"experiment_name\"].format(llm_name= llm_name_short)\n",
    "        if os.path.exists(f\"{SocialAgentBuilder.ROOT_FOLDER}output_{exp_name}.json\"):\n",
    "            print(\"Experiment \", exp_name, \"already done!\")\n",
    "            continue\n",
    "        if True:##\"easy_going\" in list(ast.literal_eval(row[\"traits\"])): #and len(list(ast.literal_eval(row[\"traits\"]))) <3 and len(list(ast.literal_eval(row[\"strategies\"]))) < 3:\n",
    "            print(\"=\"*20)\n",
    "            print(row.to_dict())\n",
    "            print(\"EXPERIMENT NAME: \", exp_name)\n",
    "            print(\"=\"*20)\n",
    "\n",
    "            social_agent = SocialAgentBuilder(\n",
    "                model_thread_id=row[\"thread_id\"],\n",
    "                llm_name = llm_name,\n",
    "                llm_num = row[\"number_of_agents\"],\n",
    "                experiment_name= exp_name,\n",
    "                temperature=temperature,\n",
    "                collaborative_strategy=list(ast.literal_eval(row[\"strategies\"])),\n",
    "                agent_trait_lst=list(ast.literal_eval(row[\"traits\"])))\n",
    "            #display(Image(social_agent.graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "\n",
    "            social_agent.run_experiment(data_type = \"validation\", save= True)\n",
    "            print(f'finished {exp_name}')\n",
    "    all_done = True\n",
    "    return all_done\n",
    "delay_in_sec = 1\n",
    "all_done = False\n",
    "while True and not all_done: \n",
    "    try:###\n",
    "        all_done = run_all_exp_settings(experiment_settings=experiment_settings)\n",
    "    except Exception as e:\n",
    "        all_done = False\n",
    "        print(f\"Exception caught: {e}, retrying in {delay_in_sec} seconds...\")\n",
    "        time.sleep(delay_in_sec)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

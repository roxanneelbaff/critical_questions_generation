from typing import Optional
from agents.Agent import Agent
from utils import extract_json_from_string

SYSTEM_PROMPT = """
Your task is to generate critical questions. The user will provide you with an intervention, and you solely reply with a single critical question.
"""

GENERATION_PROMPT = """
Generate a critical question for the following intervention:

'{intervention}'

Strictly return your critical question in the following JSON format:  
```json
{{
  'critial_question': <your generated critical question>,
}}
```

"""


class GeneratorAgent(Agent):
    def __init__(
        self,
        intervention: str,
        model_name: str,
        model_parameters: dict = {},
    ):
        super().__init__(model_name, model_parameters)

        # Agent specific parameters
        self.intervention = intervention
        self.model_name = model_name

    def _initialize(self):
        # Initialize system prompt
        message = SYSTEM_PROMPT
        self._add_to_chat(role="system", message=message)

    def _generate_critical_question(self) -> Optional[str]:
        """Generates a critical question for the given intervention.

        Returns:
            str: The critical question generated by the agent.
        """
        # Create the prompt and add to chat
        prompt = GENERATION_PROMPT.format(intervention=self.intervention)
        self._add_to_chat(role="user", message=prompt)

        # Prompt LLM and add to chat
        response = self.single_response(messages=self.chat)
        self._add_to_chat(role="assistant", message=response)

        # Process response and return
        response_dict: dict = extract_json_from_string(response)
        critical_question = response_dict.get("critical_question", None)
        if not critical_question:
            print("Error: LLM returned an invalid response. Expected JSON with key 'critical_question', but no JSON with that key was found.")
            # TODO Implement some retries here.
        return critical_question


    def _refine_critical_question(self, feedback: list[str]) -> str:
        """Refines a previously generated critical question based on the provided feedback.
        Assumes that the previously generated question is present in the chat history.

        Args:
            feedback (list[str]): List of feedback items from all Validator Agents.

        Returns:
            str: Refined critical question based on the feedback.
        """
        pass

    def generate_critical_question(self, feedback: list[str] = []) -> str:
        # Generate or refine critical question, depending on whether or not feedback exists
        if not feedback:
            critical_question = self._generate_critical_question()
        else:
            critical_question = self._refine_critical_question(feedback)

        # Return initial or refined critical question
        return critical_question
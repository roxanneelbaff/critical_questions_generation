{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q social_agents/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show social_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U pydantic\n",
    "%pip install -U \"langchain[together]\"\n",
    "%pip install -U \"langchain\"\n",
    "%pip install -U \"langgraph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "# Reading the data\n",
    "import pandas as pd\n",
    "\n",
    "from social_agents.utils import get_st_data\n",
    "\n",
    "\n",
    "for key, line in tqdm.tqdm(get_st_data(\"sample\").items()):\n",
    "    print(key)\n",
    "\n",
    "    print(line['intervention'])\n",
    "    input_text = line['intervention']\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "env, LLM, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Task: Critical thinking generation\n",
    "## Loadind Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "from langchain.chat_models import init_chat_model\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "_set_env(\"MISTRAL_API_KEY\")\n",
    "_set_env(\"TOGETHER_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"shared_task_critical_questions\"\n",
    "\n",
    "#init_chat_model(\"meta-llama/Llama-3.2-3B-Instruct-Turbo\", model_provider=\"together\", temperature= 0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#llm_name = \"gpt-4o-mini-2024-07-18\"# \"o3-mini-2025-01-31\"\n",
    "#llm_name_short = \"gpt-4o-mini_\"\n",
    "llm_dic = {\n",
    "    #\"openai_o3mini\": \"o3-mini-2025-01-31\",\n",
    "    #\"gpt-4o-mini_\": \"gpt-4o-mini-2024-07-18\",\n",
    "    \"llama8b_\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "    \"mistral24b_\": \"mistral-small-2503\",#\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    \"llama70b_\": \"meta-llama/Llama-3.3-70B-Instruct-Turbo\"\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Zero Shot LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from social_agents.agent_builder import BasicCQModel\n",
    "\n",
    "\n",
    "for llm_key, llm_full in llm_dic.items():\n",
    "    print(f\"Running {llm_key}\")\n",
    "    basic_agent = BasicCQModel(\n",
    "        model_thread_id=f\"{llm_key}_zero-shot_temp0\",\n",
    "        llm_name = llm_full,\n",
    "        llm_num = 1,\n",
    "        experiment_name= f\"{llm_key}_zero-shot_temp0\",\n",
    "        temperature=0.0)\n",
    "        \n",
    "        \n",
    "    #display(Image(basic_agent.graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "\n",
    "# RUN\n",
    "    basic_agent.run_experiment()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching all experiment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from social_agents import helper\n",
    "from social_agents.agent_builder import  SocialAgentBuilder\n",
    "\n",
    "EXPERIMENT_SETTINGS_FILE_PATH = \"output/elbaff_experiment/experiment_settings.csv\"\n",
    "override = False\n",
    "if not os.path.exists(EXPERIMENT_SETTINGS_FILE_PATH) or override:\n",
    "    print(\"generating exp settings file\")\n",
    "    exps_df = helper.generate_experiment_settings()\n",
    "    exps_df.to_csv(EXPERIMENT_SETTINGS_FILE_PATH, index=False)\n",
    "\n",
    "experiment_settings = pd.read_csv(EXPERIMENT_SETTINGS_FILE_PATH)\n",
    "experiment_settings = experiment_settings.sort_values(by=[\"rounds\", \"number_of_agents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import time\n",
    "from social_agents import data_model\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "temperature = 0.7\n",
    "llm_name_short = \"mistral24b_\"\n",
    "llm_name = llm_dic[llm_name_short]\n",
    "def run_all_exp_settings(experiment_settings):\n",
    "    all_done = False\n",
    "    for _, row in tqdm(experiment_settings.iterrows(), total=len(experiment_settings)):\n",
    "        exp_name = row[\"experiment_name\"].format(llm_name= llm_name_short)\n",
    "        if os.path.exists(f\"{SocialAgentBuilder.ROOT_FOLDER}output_{exp_name}.json\"):\n",
    "            print(\"Experiment \", exp_name, \"already done!\")\n",
    "            continue\n",
    "\n",
    "        print(\"EXPERIMENT NAME: \", exp_name)\n",
    "\n",
    "        social_agent = SocialAgentBuilder(\n",
    "            model_thread_id=row[\"thread_id\"],\n",
    "            llm_name = llm_name,\n",
    "            llm_num = row[\"number_of_agents\"],\n",
    "            experiment_name= exp_name,\n",
    "            temperature=temperature,\n",
    "            collaborative_strategy=list(ast.literal_eval(row[\"strategies\"])),\n",
    "            agent_trait_lst=list(ast.literal_eval(row[\"traits\"])))\n",
    "        #display(Image(social_agent.graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "\n",
    "        social_agent.run_experiment(data_type = \"validation\", save= True)\n",
    "        print(f'finished {exp_name}')\n",
    "    all_done = True\n",
    "    return all_done\n",
    "delay_in_sec = 0.1\n",
    "all_done = False\n",
    "while True and not all_done: \n",
    "    try:###\n",
    "        all_done = run_all_exp_settings(experiment_settings=experiment_settings)\n",
    "    except Exception as e:\n",
    "        all_done = False\n",
    "        print(f\"Exception caught: {e}, retrying in {delay_in_sec} seconds...\")\n",
    "        time.sleep(delay_in_sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import json\n",
    "len(glob.glob(\"output/elbaff_experiment/final_states/llama8b*_4R*arg*.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 %\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "l=glob.glob(\"output/elbaff_experiment/final_states/2S*arg*.json\")\n",
    "l.sort()\n",
    "len(l)\n",
    "print(round((len(l)*100)/(186*3)), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress_bar(percent: float, width: int = 50):\n",
    "    \"\"\"\n",
    "    Print a progress bar to the notebook output.\n",
    "\n",
    "    Args:\n",
    "        percent (float): Completion percentage (0.0 to 1.0).\n",
    "        width (int): Width of the progress bar in characters.\n",
    "    \"\"\"\n",
    "    filled = int(width * percent)\n",
    "    bar = \"â–ˆ\" * filled + \"-\" * (width - filled)\n",
    "    print(f\"[{bar}] {percent * 100:.1f}%\", end=\"\\r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m num_runs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# e.g., for 1 hour (6 x 10 minutes)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_runs):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Your code here\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     l\u001b[38;5;241m=\u001b[39m\u001b[43mglob\u001b[49m\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput/elbaff_experiment/final_states/2S*arg*.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#print(round((len(l)*100)/(186*3)), \"%\")\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     print_progress_bar((\u001b[38;5;28mlen\u001b[39m(l)\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m186\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "i,port glob\n",
    "# Number of iterations (set to None or a high number if you want it to run indefinitely)\n",
    "num_runs = 6*3  # e.g., for 1 hour (6 x 10 minutes)\n",
    "\n",
    "for i in range(num_runs):\n",
    "    # Your code here\n",
    "    l=glob.glob(\"output/elbaff_experiment/final_states/2S*arg*.json\")\n",
    "    #print(round((len(l)*100)/(186*3)), \"%\")\n",
    "    print_progress_bar((len(l)/(186*3)))\n",
    "    # Wait for 10 minutes (600 seconds)\n",
    "    if i < num_runs - 1:  # Don't sleep after the last run\n",
    "        time.sleep(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

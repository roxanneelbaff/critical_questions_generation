{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q social_agents/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain_mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show social_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U pydantic\n",
    "%pip install -U \"langchain[together]\"\n",
    "%pip install -U \"langchain\"\n",
    "%pip install -U \"langgraph\"\n",
    "%pip install -U \"langgraph-mistralai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "# Reading the data\n",
    "import pandas as pd\n",
    "\n",
    "from social_agents.utils import get_st_data\n",
    "\n",
    "\n",
    "for key, line in tqdm.tqdm(get_st_data(\"sample\").items()):\n",
    "    print(key)\n",
    "\n",
    "    print(line['intervention'])\n",
    "    input_text = line['intervention']\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "env, LLM, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Task: Critical thinking generation\n",
    "## Loadind Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "_set_env(\"MISTRAL_API_KEY\")\n",
    "_set_env(\"TOGETHER_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"shared_task_critical_questions\"\n",
    "\n",
    "#init_chat_model(\"meta-llama/Llama-3.2-3B-Instruct-Turbo\", model_provider=\"together\", temperature= 0.7)\n",
    "os.environ[\"MISTRAL_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Zero Shot LLM to start with o3-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from social_agents.agent_builder import BasicCQModel\n",
    "model_name = \"o3-mini\"\n",
    "\n",
    "basic_agent = BasicCQModel(llm_name = model_name, temperature=None ) #interrupt_before=['human_feedback'], checkpointer=memory)\n",
    "\n",
    "\n",
    "display(Image(basic_agent.graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "\n",
    "# RUN\n",
    "# basic_agent.run_experiment()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "### Evaulate \n",
    "\n",
    "- Run shell \n",
    "\n",
    "```shell\n",
    "\n",
    "python3 eval_scripts/evaluation.py \\\n",
    "    --metric similarity \\\n",
    "    --input_path data_splits/validation.json \\\n",
    "    --submission_path output/elbaff_experiment/output_gpt-4o-mini-2024-07-18social_n2_Te_Sr.json \\\n",
    "    --threshold 0.6 \n",
    "\n",
    "```\n",
    "\n",
    "- OUTPUT : output/output_o3-mini_temperatureNA._eval_similarity_06.json\n",
    "\n",
    "\n",
    "\n",
    "**Overall count**\n",
    "\n",
    "| **Questions Labels** |  **#**  | **ratio** |\n",
    "|:--------------------|-------:|---------:|\n",
    "| useful               | **329** |  **0,59** |\n",
    "| unhelpful            |      63 |      0,11 |\n",
    "| Invalid              |       8 |      0,01 |\n",
    "| Not able to evaluate |     158 |      0,28 |\n",
    "| **Total**            | **558** |         1 |\n",
    "\n",
    "\n",
    "**Overall count within each argument**\n",
    "\n",
    "| **n/3 useful questions per arg** | **# of arguments** | **ratio** |\n",
    "|:-------------------------------:|-------------------:|:---------:|\n",
    "|                               0/3 |                 17 |      0,10 |\n",
    "|                               1/3 |                 51 |      0,27 |\n",
    "|                               2/3 |             **76** |      0,40 |\n",
    "|                               3/3 |                 42 |      0,23 |\n",
    "| **Total**                       |            **186** |         1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from social_agents import helper\n",
    "from social_agents.agent_builder import  CQSTAbstractAgent, SocialAgentBuilder\n",
    "\n",
    "EXPERIMENT_SETTINGS_FILE_PATH = \"output/elbaff_experiment/experiment_settings.csv\"\n",
    "override = False\n",
    "if not os.path.exists(EXPERIMENT_SETTINGS_FILE_PATH) or override:\n",
    "    print(\"generating exp settings file\")\n",
    "    exps_df = helper.generate_experiment_settings()\n",
    "    exps_df.to_csv(EXPERIMENT_SETTINGS_FILE_PATH, index=False)\n",
    "\n",
    "experiment_settings = pd.read_csv(EXPERIMENT_SETTINGS_FILE_PATH)\n",
    "experiment_settings.head()\n",
    "\n",
    "# exp_row = experiment_settings.iloc[20].to_dict()\n",
    "# exp_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_settings = experiment_settings.sort_values(by=[\"rounds\", \"number_of_agents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from social_agents.data_model import CriticalQuestionList\n",
    "prompt = \"\"\"\n",
    "# Context:\n",
    "You are tasked with generating critical questions that examine the underlying assumptions and logic of an argumentative text. Given a real debate argument, your goal is to assess its acceptability and potential fallacies.\n",
    "\n",
    "# Argument:\n",
    "\n",
    "'''\n",
    "CLINTON: \"nine million people lost their jobs\n",
    "Five million people lost their homes\n",
    "$ 13 trillion in family wealth was wiped out\n",
    "Now , we have come back from that abyss\n",
    "it has not been easy\n",
    "we 're now on the precipice of having a potentially much better economy\n",
    "the last thing we need to do is to go back to the policies that failed us in the first place\n",
    "Independent experts have looked at what I 've proposed\n",
    "looked at what Donald 's proposed\n",
    "I intend to get it done\n",
    "Take clean energy\n",
    "Some country is going to be the clean- energy superpower of the 21st century\n",
    "Donald thinks that climate change is a hoax perpetrated by the Chinese\n",
    "I think it 's real\"\n",
    "'''\n",
    "\n",
    "# Instructions:\n",
    "- Read the argument carefully.\n",
    "- Generate three critical questions that:\n",
    "    - Uncover the assumptions behind the argument's premises.\n",
    "    - Challenge the strength of its inferences.\n",
    "- Ensure your questions are specific to the given argument and not generic.\n",
    "\n",
    "\"\"\"\n",
    "rsponse = init_chat_model(\"mistral-small-2503\",\n",
    "                model_provider=\"mistralai\",\n",
    "                temperature=0.7).with_structured_output(CriticalQuestionList, include_raw=True).invoke(prompt)\n",
    "rsponse\n",
    "# cq_ = CriticalQuestionList(rsponse)\n",
    "#print(type(cq_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import time\n",
    "from social_agents import data_model\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "#llm_name = \"gpt-4o-mini-2024-07-18\"# \"o3-mini-2025-01-31\"\n",
    "#llm_name_short = \"gpt-4o-mini_\"\n",
    "llm_dic = {\n",
    "    \"openai_o3mini\": \"o3-mini-2025-01-31\",\n",
    "    \"gpt-4o-mini_\": \"gpt-4o-mini-2024-07-18\",\n",
    "    #\"llam3b_\": \"meta-llama/Llama-3.2-3B-Instruct-Turbo\",\n",
    "    \"llama8b_\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "    \"mistral24b_\": \"mistral-small-2503\",#\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    #\"llama8blite_\": \"meta-llama/Meta-Llama-3-8B-Instruct-Lite\",\n",
    "    \"llama70b_\": \"meta-llama/Llama-3.3-70B-Instruct-Turbo\"\n",
    "\n",
    "}\n",
    "\n",
    "#mistralai/Mixtral-8x22B-Instruct-v0.1\n",
    "#mistralai/Mistral-7B-Instruct-v0.3\n",
    "#mistralai/Mixtral-8x7B-Instruct-v0.1\n",
    "temperature = 0.7\n",
    "llm_name_short = \"mistral24b_\"\n",
    "llm_name = llm_dic[llm_name_short]\n",
    "def run_all_exp_settings(experiment_settings):\n",
    "    all_done = False\n",
    "    for _, row in tqdm(experiment_settings.iterrows(), total=len(experiment_settings)):\n",
    "        exp_name = row[\"experiment_name\"].format(llm_name= llm_name_short)\n",
    "        if os.path.exists(f\"{SocialAgentBuilder.ROOT_FOLDER}output_{exp_name}.json\"):\n",
    "            print(\"Experiment \", exp_name, \"already done!\")\n",
    "            continue\n",
    "        if True:##\"easy_going\" in list(ast.literal_eval(row[\"traits\"])): #and len(list(ast.literal_eval(row[\"traits\"]))) <3 and len(list(ast.literal_eval(row[\"strategies\"]))) < 3:\n",
    "            print(\"=\"*20)\n",
    "            print(row.to_dict())\n",
    "            print(\"EXPERIMENT NAME: \", exp_name)\n",
    "            print(\"=\"*20)\n",
    "\n",
    "            social_agent = SocialAgentBuilder(\n",
    "                model_thread_id=row[\"thread_id\"],\n",
    "                llm_name = llm_name,\n",
    "                llm_num = row[\"number_of_agents\"],\n",
    "                experiment_name= exp_name,\n",
    "                temperature=temperature,\n",
    "                collaborative_strategy=list(ast.literal_eval(row[\"strategies\"])),\n",
    "                agent_trait_lst=list(ast.literal_eval(row[\"traits\"])))\n",
    "            #display(Image(social_agent.graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "\n",
    "            social_agent.run_experiment(data_type = \"validation\", save= True)\n",
    "            print(f'finished {exp_name}')\n",
    "    all_done = True\n",
    "    return all_done\n",
    "delay_in_sec = 1\n",
    "all_done = False\n",
    "while True and not all_done: \n",
    "    try:###\n",
    "        all_done = run_all_exp_settings(experiment_settings=experiment_settings)\n",
    "    except Exception as e:\n",
    "        all_done = False\n",
    "        print(f\"Exception caught: {e}, retrying in {delay_in_sec} seconds...\")\n",
    "        time.sleep(delay_in_sec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best w perfomer\n",
    "-> \"mistral 8x7b\"\n",
    "-> \"4o\"\n",
    "small are \n",
    "\n",
    "# Future prompting\n",
    "few shot \n",
    "\n",
    "# Best for validators\n",
    "llama 3.1 3b --> w aggregator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

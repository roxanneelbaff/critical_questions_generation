{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "Running command: python eval_scripts/evaluation.py --metric similarity --input_path data_splits/validation.json --submission_path output/elbaff_experiment/output_llama8b_social_n3_Teee_Srrr.json --threshold 0.6\n",
      "Distribution of the labels: Counter({'Useful': 382, 'not_able_to_evaluate': 102, 'Unhelpful': 49, 'Invalid': 25})\n",
      "Distribution of the intervention punctuation: Counter({1.0: 73, 0.6666666666666666: 60, 0.3333333333333333: 43, 0: 10})\n",
      "Overall punctuation 0.6845878136200716\n",
      "\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "Running command: python eval_scripts/evaluation.py --metric similarity --input_path data_splits/validation.json --submission_path output/elbaff_experiment/output_llama8b_social_n3_Teee_Sdrr.json --threshold 0.6\n",
      "Distribution of the labels: Counter({'Useful': 363, 'not_able_to_evaluate': 109, 'Unhelpful': 66, 'Invalid': 20})\n",
      "Distribution of the intervention punctuation: Counter({0.6666666666666666: 69, 1.0: 62, 0.3333333333333333: 39, 0: 16})\n",
      "Overall punctuation 0.6505376344086023\n",
      "\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "Running command: python eval_scripts/evaluation.py --metric similarity --input_path data_splits/validation.json --submission_path output/elbaff_experiment/output_llama8b_social_n3_Teeo_Srdd.json --threshold 0.6\n",
      "Distribution of the labels: Counter({'Useful': 353, 'not_able_to_evaluate': 107, 'Unhelpful': 77, 'Invalid': 18})\n",
      "Distribution of the intervention punctuation: Counter({0.6666666666666666: 73, 1.0: 53, 0.3333333333333333: 48, 0: 12})\n",
      "Overall punctuation 0.6326164874551972\n",
      "\n",
      "already evaluated\n",
      "Running command: python eval_scripts/evaluation.py --metric similarity --input_path data_splits/validation.json --submission_path output/elbaff_experiment/output_llama8b_social_n3_Teee_Srdd.json --threshold 0.6\n",
      "Distribution of the labels: Counter({'Useful': 397, 'not_able_to_evaluate': 81, 'Unhelpful': 58, 'Invalid': 22})\n",
      "Distribution of the intervention punctuation: Counter({1.0: 74, 0.6666666666666666: 71, 0.3333333333333333: 33, 0: 8})\n",
      "Overall punctuation 0.7114695340501795\n",
      "\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "Running command: python eval_scripts/evaluation.py --metric similarity --input_path data_splits/validation.json --submission_path output/elbaff_experiment/output_llama8b_social_n3_Teeo_Sdrr.json --threshold 0.6\n",
      "Distribution of the labels: Counter({'Useful': 378, 'not_able_to_evaluate': 103, 'Unhelpful': 60, 'Invalid': 17})\n",
      "Distribution of the intervention punctuation: Counter({1.0: 69, 0.6666666666666666: 66, 0.3333333333333333: 39, 0: 12})\n",
      "Overall punctuation 0.67741935483871\n",
      "\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "Running command: python eval_scripts/evaluation.py --metric similarity --input_path data_splits/validation.json --submission_path output/elbaff_experiment/output_llama8b_social_n3_Teeo_Srrr.json --threshold 0.6\n",
      "Distribution of the labels: Counter({'Useful': 369, 'not_able_to_evaluate': 99, 'Unhelpful': 66, 'Invalid': 24})\n",
      "Distribution of the intervention punctuation: Counter({0.6666666666666666: 72, 1.0: 61, 0.3333333333333333: 42, 0: 11})\n",
      "Overall punctuation 0.6612903225806455\n",
      "\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "Running command: python eval_scripts/evaluation.py --metric similarity --input_path data_splits/validation.json --submission_path output/elbaff_experiment/output_llama8b_social_n3_Teee_Sddd.json --threshold 0.6\n",
      "Distribution of the labels: Counter({'Useful': 368, 'not_able_to_evaluate': 100, 'Unhelpful': 56, 'Invalid': 32})\n",
      "Distribution of the intervention punctuation: Counter({1.0: 70, 0.6666666666666666: 60, 0.3333333333333333: 38, 0: 18})\n",
      "Overall punctuation 0.6594982078853046\n",
      "\n",
      "already evaluated\n",
      "Running command: python eval_scripts/evaluation.py --metric similarity --input_path data_splits/validation.json --submission_path output/elbaff_experiment/output_llama8b_social_n3_Teee_Sddr.json --threshold 0.6\n",
      "Distribution of the labels: Counter({'Useful': 361, 'not_able_to_evaluate': 104, 'Unhelpful': 65, 'Invalid': 28})\n",
      "Distribution of the intervention punctuation: Counter({0.6666666666666666: 68, 1.0: 61, 0.3333333333333333: 42, 0: 15})\n",
      "Overall punctuation 0.6469534050179212\n",
      "\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "Running command: python eval_scripts/evaluation.py --metric similarity --input_path data_splits/validation.json --submission_path output/elbaff_experiment/output_llama8b_social_n3_Teeo_Srrd.json --threshold 0.6\n",
      "Distribution of the labels: Counter({'Useful': 357, 'not_able_to_evaluate': 116, 'Unhelpful': 63, 'Invalid': 20})\n",
      "Distribution of the intervention punctuation: Counter({0.6666666666666666: 76, 1.0: 59, 0.3333333333333333: 28, 0: 23})\n",
      "Overall punctuation 0.6397849462365596\n",
      "\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "Running command: python eval_scripts/evaluation.py --metric similarity --input_path data_splits/validation.json --submission_path output/elbaff_experiment/output_llama8b_social_n3_Teeo_Sdrd.json --threshold 0.6\n",
      "Distribution of the labels: Counter({'Useful': 356, 'not_able_to_evaluate': 115, 'Unhelpful': 66, 'Invalid': 21})\n",
      "Distribution of the intervention punctuation: Counter({0.6666666666666666: 73, 1.0: 55, 0.3333333333333333: 45, 0: 13})\n",
      "Overall punctuation 0.6379928315412188\n",
      "\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "Running command: python eval_scripts/evaluation.py --metric similarity --input_path data_splits/validation.json --submission_path output/elbaff_experiment/output_llama8b_social_n3_Teee_Srdr.json --threshold 0.6\n",
      "Distribution of the labels: Counter({'Useful': 371, 'not_able_to_evaluate': 108, 'Unhelpful': 61, 'Invalid': 18})\n",
      "Distribution of the intervention punctuation: Counter({0.6666666666666666: 75, 1.0: 63, 0.3333333333333333: 32, 0: 16})\n",
      "Overall punctuation 0.6648745519713266\n",
      "\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "Running command: python eval_scripts/evaluation.py --metric similarity --input_path data_splits/validation.json --submission_path output/elbaff_experiment/output_llama8b_social_n3_Teeo_Srdr.json --threshold 0.6\n",
      "Distribution of the labels: Counter({'Useful': 356, 'not_able_to_evaluate': 122, 'Unhelpful': 57, 'Invalid': 23})\n",
      "Distribution of the intervention punctuation: Counter({0.6666666666666666: 70, 1.0: 58, 0.3333333333333333: 42, 0: 16})\n",
      "Overall punctuation 0.6379928315412188\n",
      "\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "Running command: python eval_scripts/evaluation.py --metric similarity --input_path data_splits/validation.json --submission_path output/elbaff_experiment/output_llama8b_social_n3_Teee_Sdrd.json --threshold 0.6\n",
      "Distribution of the labels: Counter({'Useful': 365, 'not_able_to_evaluate': 90, 'Unhelpful': 79, 'Invalid': 24})\n",
      "Distribution of the intervention punctuation: Counter({1.0: 69, 0.6666666666666666: 56, 0.3333333333333333: 46, 0: 15})\n",
      "Overall punctuation 0.654121863799283\n",
      "\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "Running command: python eval_scripts/evaluation.py --metric similarity --input_path data_splits/validation.json --submission_path output/elbaff_experiment/output_llama8b_social_n3_Teee_Srrd.json --threshold 0.6\n",
      "Distribution of the labels: Counter({'Useful': 364, 'not_able_to_evaluate': 106, 'Unhelpful': 67, 'Invalid': 21})\n",
      "Distribution of the intervention punctuation: Counter({0.6666666666666666: 73, 1.0: 61, 0.3333333333333333: 35, 0: 17})\n",
      "Overall punctuation 0.652329749103943\n",
      "\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n",
      "already evaluated\n"
     ]
    }
   ],
   "source": [
    "from social_agents.agent_builder import SocialAgentBuilder\n",
    "from social_agents.utils import eval_experiment\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "all_results_path = SocialAgentBuilder.ROOT_FOLDER + \"experiment_results.csv\"\n",
    "path_ = SocialAgentBuilder.ROOT_FOLDER + \"output_*.json\"\n",
    "time_log_path = SocialAgentBuilder.ROOT_FOLDER + \"time_log.csv\"\n",
    "\n",
    "out_files = [x for x in glob(path_) if x.find(\"_eval_\") == -1]\n",
    "evaluated_files = [x for x in glob(path_) if x.find(\"_eval_\") > -1]\n",
    "\n",
    "data_split = \"validation\"\n",
    "threshold = 0.6\n",
    "metric = \"similarity\"\n",
    "\n",
    "\n",
    "all_results = []\n",
    "for out_ in out_files:\n",
    "    eval_name = out_.replace(\"json\", f\"_eval_{metric}_{str(threshold).replace('.', '')}.json\")\n",
    "    if eval_name in evaluated_files:\n",
    "        print(\"already evaluated\")\n",
    "        continue\n",
    "    \n",
    "    exp_name = os.path.basename(out_).replace(\"output_\", \"\").replace(\".json\", \"\")\n",
    "    eval_dict = {\"experiment_name\": exp_name}\n",
    "    eval_dict = eval_dict | eval_experiment(submission_path=out_, data_split=data_split, threshold=threshold)\n",
    "\n",
    "    time_log_df = pd.read_csv(time_log_path)\n",
    "    if exp_name not in time_log_df.columns:\n",
    "        print(f\"time not logged for {exp_name}\")\n",
    "    else:\n",
    "        eval_dict[\"time_mean\"] = time_log_df[exp_name].mean()\n",
    "        eval_dict[\"time_std\"] = time_log_df[exp_name].std()\n",
    "\n",
    "    try:\n",
    "        all_experiments_results_df = pd.read_csv(all_results_path)\n",
    "        all_experiments_results_df = all_experiments_results_df.drop(columns=[col for col in all_experiments_results_df.columns if col.startswith('Unnamed')])\n",
    "    except FileNotFoundError:\n",
    "        all_experiments_results_df = pd.DataFrame()\n",
    "    \n",
    "\n",
    "    all_experiments_results_df = pd.concat([all_experiments_results_df, pd.DataFrame([eval_dict])], ignore_index=True)\n",
    "    all_experiments_results_df.to_csv(all_results_path, index=False)\n",
    "    all_results.append(eval_dict)\n",
    "\n",
    "new_results_df = pd.DataFrame(all_results)\n",
    "all_experiments_results_df = pd.read_csv(all_results_path)\n",
    "summary_df = all_experiments_results_df[[\"experiment_name\", \"Useful_ratio\", \"3/3_ratio\", \"overall_punctuation\", \"time_mean\", \"time_std\"]]\n",
    "summary_df.to_csv(all_results_path.replace(\".csv\", \"_summary.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>Useful</th>\n",
       "      <th>not_able_to_evaluate</th>\n",
       "      <th>Unhelpful</th>\n",
       "      <th>Invalid</th>\n",
       "      <th>Useful_ratio</th>\n",
       "      <th>not_able_to_evaluate_ratio</th>\n",
       "      <th>Unhelpful_ratio</th>\n",
       "      <th>Invalid_ratio</th>\n",
       "      <th>3/3</th>\n",
       "      <th>2/3</th>\n",
       "      <th>1/3</th>\n",
       "      <th>0/3</th>\n",
       "      <th>3/3_ratio</th>\n",
       "      <th>2/3_ratio</th>\n",
       "      <th>1/3_ratio</th>\n",
       "      <th>0/3_ratio</th>\n",
       "      <th>overall_punctuation</th>\n",
       "      <th>time_mean</th>\n",
       "      <th>time_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama8b_social_n3_Teee_Srrr</td>\n",
       "      <td>382</td>\n",
       "      <td>102</td>\n",
       "      <td>49</td>\n",
       "      <td>25</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>73</td>\n",
       "      <td>60</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.684588</td>\n",
       "      <td>0.271658</td>\n",
       "      <td>1.440042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama8b_social_n3_Teee_Sdrr</td>\n",
       "      <td>363</td>\n",
       "      <td>109</td>\n",
       "      <td>66</td>\n",
       "      <td>20</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>62</td>\n",
       "      <td>69</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.650538</td>\n",
       "      <td>0.175149</td>\n",
       "      <td>1.226887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama8b_social_n3_Teeo_Srdd</td>\n",
       "      <td>353</td>\n",
       "      <td>107</td>\n",
       "      <td>77</td>\n",
       "      <td>18</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>53</td>\n",
       "      <td>73</td>\n",
       "      <td>48</td>\n",
       "      <td>12</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.632616</td>\n",
       "      <td>0.043552</td>\n",
       "      <td>0.590147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama8b_social_n3_Teee_Srdd</td>\n",
       "      <td>397</td>\n",
       "      <td>81</td>\n",
       "      <td>58</td>\n",
       "      <td>22</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>74</td>\n",
       "      <td>71</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.711470</td>\n",
       "      <td>0.749983</td>\n",
       "      <td>2.812153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama8b_social_n3_Teeo_Sdrr</td>\n",
       "      <td>378</td>\n",
       "      <td>103</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>69</td>\n",
       "      <td>66</td>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.077598</td>\n",
       "      <td>0.742544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               experiment_name  Useful  not_able_to_evaluate  Unhelpful  \\\n",
       "0  llama8b_social_n3_Teee_Srrr     382                   102         49   \n",
       "1  llama8b_social_n3_Teee_Sdrr     363                   109         66   \n",
       "2  llama8b_social_n3_Teeo_Srdd     353                   107         77   \n",
       "3  llama8b_social_n3_Teee_Srdd     397                    81         58   \n",
       "4  llama8b_social_n3_Teeo_Sdrr     378                   103         60   \n",
       "\n",
       "   Invalid  Useful_ratio  not_able_to_evaluate_ratio  Unhelpful_ratio  \\\n",
       "0       25          0.68                        0.18             0.09   \n",
       "1       20          0.65                        0.20             0.12   \n",
       "2       18          0.64                        0.19             0.14   \n",
       "3       22          0.71                        0.15             0.10   \n",
       "4       17          0.68                        0.18             0.11   \n",
       "\n",
       "   Invalid_ratio  3/3  2/3  1/3  0/3  3/3_ratio  2/3_ratio  1/3_ratio  \\\n",
       "0           0.04   73   60   43   10       0.39       0.32       0.23   \n",
       "1           0.04   62   69   39   16       0.33       0.37       0.21   \n",
       "2           0.03   53   73   48   12       0.28       0.39       0.26   \n",
       "3           0.04   74   71   33    8       0.40       0.38       0.18   \n",
       "4           0.03   69   66   39   12       0.37       0.35       0.21   \n",
       "\n",
       "   0/3_ratio  overall_punctuation  time_mean  time_std  \n",
       "0       0.05             0.684588   0.271658  1.440042  \n",
       "1       0.09             0.650538   0.175149  1.226887  \n",
       "2       0.06             0.632616   0.043552  0.590147  \n",
       "3       0.04             0.711470   0.749983  2.812153  \n",
       "4       0.06             0.677419   0.077598  0.742544  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiments_results_df.sort_values(by=\"overa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>Useful_ratio</th>\n",
       "      <th>3/3_ratio</th>\n",
       "      <th>overall_punctuation</th>\n",
       "      <th>time_mean</th>\n",
       "      <th>time_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>gpt-4o-mini_social_n1_Te_Sr</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>10.956791</td>\n",
       "      <td>2.838868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4o-mini_social_n1_Te_Sr</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>10.956791</td>\n",
       "      <td>2.838868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4o-mini_social_n1_Te_Srr</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>14.625542</td>\n",
       "      <td>2.615584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt-4o-mini_social_n1_Te_Srr</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>14.625542</td>\n",
       "      <td>2.615584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>llama8b_social_n3_Teee_Srdd</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.711470</td>\n",
       "      <td>0.749983</td>\n",
       "      <td>2.812153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>llama8b_social_n3_Teee_Srd</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.700717</td>\n",
       "      <td>0.078821</td>\n",
       "      <td>0.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>llama8b_social_n3_Teoo_Sd</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.133770</td>\n",
       "      <td>0.643908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>llama8b_social_n2_Tee_Sdd</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.109199</td>\n",
       "      <td>0.665749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>llama8b_social_n3_Teeo_Sdr</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.689964</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>0.542073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>llama8b_social_n3_Teoo_Srr</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.689964</td>\n",
       "      <td>0.286844</td>\n",
       "      <td>1.553684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  experiment_name  Useful_ratio  3/3_ratio  \\\n",
       "32    gpt-4o-mini_social_n1_Te_Sr          0.73       0.43   \n",
       "1     gpt-4o-mini_social_n1_Te_Sr          0.73       0.43   \n",
       "0    gpt-4o-mini_social_n1_Te_Srr          0.73       0.42   \n",
       "19   gpt-4o-mini_social_n1_Te_Srr          0.73       0.42   \n",
       "124   llama8b_social_n3_Teee_Srdd          0.71       0.40   \n",
       "57     llama8b_social_n3_Teee_Srd          0.70       0.42   \n",
       "43      llama8b_social_n3_Teoo_Sd          0.69       0.40   \n",
       "34      llama8b_social_n2_Tee_Sdd          0.70       0.42   \n",
       "54     llama8b_social_n3_Teeo_Sdr          0.69       0.39   \n",
       "51     llama8b_social_n3_Teoo_Srr          0.69       0.39   \n",
       "\n",
       "     overall_punctuation  time_mean  time_std  \n",
       "32              0.725806  10.956791  2.838868  \n",
       "1               0.725806  10.956791  2.838868  \n",
       "0               0.725806  14.625542  2.615584  \n",
       "19              0.725806  14.625542  2.615584  \n",
       "124             0.711470   0.749983  2.812153  \n",
       "57              0.700717   0.078821  0.754161  \n",
       "43              0.693548   0.133770  0.643908  \n",
       "34              0.693548   0.109199  0.665749  \n",
       "54              0.689964   0.040300  0.542073  \n",
       "51              0.689964   0.286844  1.553684  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.sort_values(by=\"overall_punctuation\", ascending=False)[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiments_results_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob(\"output/elbaff_experiment/final_states/*.json\")\n",
    "\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "fail_fs = []\n",
    "numbers = []\n",
    "correct_n=[]\n",
    "for f in files:\n",
    "    with open(f, \"r\") as f_:\n",
    "        s = json.load(f_)\n",
    "        if len(s['final_cq']['critical_questions']) != 3:\n",
    "            numbers.append(len(s['final_cq']['critical_questions']))\n",
    "            fail_fs.append(f)\n",
    "        else:\n",
    "            correct_n.append(len(s['final_cq']['critical_questions']))\n",
    "\n",
    "\n",
    "Counter(numbers).values()\n",
    "#Counter(correct_n)\n",
    "fail_fs = list(set(fail_fs))\n",
    "len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for ffail in fail_fs:\n",
    "    if os.path.exists(ffail):\n",
    "        os.remove(ffail)\n",
    "    else:\n",
    "        print(\"Doesnt exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted = fail_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
